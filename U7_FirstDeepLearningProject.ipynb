{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 Your First Deep Learning Project in Python with Keras Step-By-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda update mkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source:\n",
    "\n",
    "This practical is based on the blog post:\n",
    "\n",
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "Here we are going to reproduce parts of that post.\n",
    "I recommend using Anaconda Python, read the installation guide for it under Unit 7. Use Python 3.x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Prerequisites:\n",
    "Libraries used in this tutorial:\n",
    "- keras (now built into TensorFlow)\n",
    "- numpy\n",
    "- sklearn\n",
    "- pydot\n",
    "\n",
    "External libraries (necessary for visualization):\n",
    "- https://graphviz.gitlab.io/download/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you set up your machine at home you can remove the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from pydot) (3.0.4)\n",
      "Requirement already satisfied: graphviz in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (0.18.2)\n",
      "Requirement already satisfied: tensorflow in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/rahulpandiri/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets used\n",
    "Please download the following datasets and put them into the folder, where this notebook is located (i.e. your working directory):\n",
    "- https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
    "- http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
    "- https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# For plotting layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Pima Indian dataset\n",
    "\n",
    "It is a csv file with ',' as delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables can be summarized as follows:\n",
    "\n",
    "Input Variables (X):\n",
    "\n",
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function\n",
    "8. Age (years)\n",
    "\n",
    "Output Variables (Y):\n",
    "\n",
    "1. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0\n",
    "What is the size of this dataset? Take a look at a few rows of this dataset to make sure you understand the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model expects rows of data with 8 variables (the input_dim=8 argument)\n",
    "- The first hidden layer has 12 nodes and uses the relu activation function.\n",
    "- The second hidden layer has 8 nodes and uses the relu activation function.\n",
    "- The output layer has one node and uses the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 21:05:01.993261: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-26 21:05:01.994428: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# define the Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Check your model \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a neural network model you will need to specify a loss function, an optimizer, and some metrics for monitoring.\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/train_and_evaluate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the Keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 696us/step - loss: 8.4247 - accuracy: 0.6471\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 1.1789 - accuracy: 0.4961\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.8058 - accuracy: 0.5664\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.7273 - accuracy: 0.6211\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.6931 - accuracy: 0.6146\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.6662 - accuracy: 0.6484\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.6552 - accuracy: 0.6380\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.6462 - accuracy: 0.6628\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.6430 - accuracy: 0.6667\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.6341 - accuracy: 0.6549\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.6361 - accuracy: 0.6745\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.6138 - accuracy: 0.6771\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.6048 - accuracy: 0.6979\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.6108 - accuracy: 0.6875\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.6048 - accuracy: 0.6888\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.5916 - accuracy: 0.6979\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5867 - accuracy: 0.7018\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5784 - accuracy: 0.7005\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5738 - accuracy: 0.6940\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5731 - accuracy: 0.7122\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5648 - accuracy: 0.7188\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.5730 - accuracy: 0.7083\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5607 - accuracy: 0.7122\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5869 - accuracy: 0.6797\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5574 - accuracy: 0.7383\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5608 - accuracy: 0.7070\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5735 - accuracy: 0.7070\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5678 - accuracy: 0.7174\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5645 - accuracy: 0.7161\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5428 - accuracy: 0.7331\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5527 - accuracy: 0.7318\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5616 - accuracy: 0.7122\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5413 - accuracy: 0.7370\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5440 - accuracy: 0.7148\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5467 - accuracy: 0.7240\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5539 - accuracy: 0.7370\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5451 - accuracy: 0.7318\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5347 - accuracy: 0.7135\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5272 - accuracy: 0.7448\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5262 - accuracy: 0.7539\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5343 - accuracy: 0.7422\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5322 - accuracy: 0.7383\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5266 - accuracy: 0.7448\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5356 - accuracy: 0.7474\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5274 - accuracy: 0.7461\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5231 - accuracy: 0.7513\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5291 - accuracy: 0.7318\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5260 - accuracy: 0.7383\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5250 - accuracy: 0.7448\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5209 - accuracy: 0.7383\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5235 - accuracy: 0.7383\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.5178 - accuracy: 0.7422\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5126 - accuracy: 0.7552\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5304 - accuracy: 0.7409\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5140 - accuracy: 0.7526\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5220 - accuracy: 0.7552\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5272 - accuracy: 0.7396\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5146 - accuracy: 0.7552\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5246 - accuracy: 0.7500\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5108 - accuracy: 0.7565\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5136 - accuracy: 0.7617\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5151 - accuracy: 0.7552\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.5109 - accuracy: 0.7552\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 137us/step - loss: 0.5235 - accuracy: 0.7448\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.5029 - accuracy: 0.7591\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.5118 - accuracy: 0.7500\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.5065 - accuracy: 0.7682\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.5087 - accuracy: 0.7708\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 143us/step - loss: 0.5104 - accuracy: 0.7552\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 157us/step - loss: 0.5034 - accuracy: 0.7578\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.5283 - accuracy: 0.7370\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 145us/step - loss: 0.5145 - accuracy: 0.7513\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 137us/step - loss: 0.5021 - accuracy: 0.7578\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.5060 - accuracy: 0.7695\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.5146 - accuracy: 0.7357\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 137us/step - loss: 0.5116 - accuracy: 0.7565\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 135us/step - loss: 0.4966 - accuracy: 0.7591\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 136us/step - loss: 0.4988 - accuracy: 0.7591\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5110 - accuracy: 0.7552\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4924 - accuracy: 0.7656\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.4958 - accuracy: 0.7708\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.5104 - accuracy: 0.7591\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.5021 - accuracy: 0.7565\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5000 - accuracy: 0.7565\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.5171 - accuracy: 0.7539\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.5355 - accuracy: 0.7357\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 135us/step - loss: 0.5161 - accuracy: 0.7539\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 135us/step - loss: 0.4979 - accuracy: 0.7682\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 135us/step - loss: 0.4977 - accuracy: 0.7526\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.4926 - accuracy: 0.7539\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.4996 - accuracy: 0.7578\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4899 - accuracy: 0.7695\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4930 - accuracy: 0.7695\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4853 - accuracy: 0.7734\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4986 - accuracy: 0.7500\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.4908 - accuracy: 0.7734\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4947 - accuracy: 0.7539\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4987 - accuracy: 0.7591\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.4946 - accuracy: 0.7578\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4966 - accuracy: 0.7617\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4955 - accuracy: 0.7617\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.4876 - accuracy: 0.7734\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.4872 - accuracy: 0.7643\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5086 - accuracy: 0.7487\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4887 - accuracy: 0.7773\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.4908 - accuracy: 0.7708\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4808 - accuracy: 0.7799\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4868 - accuracy: 0.7695\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4975 - accuracy: 0.7669\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4988 - accuracy: 0.7513\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.4943 - accuracy: 0.7643\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4861 - accuracy: 0.7695\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4807 - accuracy: 0.7721\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4838 - accuracy: 0.7708\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4875 - accuracy: 0.7669\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4869 - accuracy: 0.7812\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4886 - accuracy: 0.7591\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4869 - accuracy: 0.7656\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4900 - accuracy: 0.7643\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4854 - accuracy: 0.7708\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.4869 - accuracy: 0.7695\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.4794 - accuracy: 0.7721\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4884 - accuracy: 0.7773\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.4984 - accuracy: 0.7682\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4812 - accuracy: 0.7760\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4767 - accuracy: 0.7747\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4883 - accuracy: 0.7695\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4757 - accuracy: 0.7812\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4798 - accuracy: 0.7669\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.4728 - accuracy: 0.7591\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4760 - accuracy: 0.7786\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4822 - accuracy: 0.7617\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4782 - accuracy: 0.7773\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.4766 - accuracy: 0.7734\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4822 - accuracy: 0.7721\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4755 - accuracy: 0.7591\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4714 - accuracy: 0.7786\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4759 - accuracy: 0.7734\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.4839 - accuracy: 0.7617\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4808 - accuracy: 0.7682\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4730 - accuracy: 0.7747\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4788 - accuracy: 0.7591\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4713 - accuracy: 0.7721\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4740 - accuracy: 0.7786\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4837 - accuracy: 0.7656\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4758 - accuracy: 0.7630\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4712 - accuracy: 0.7786\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4690 - accuracy: 0.7826\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4648 - accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "# fit the Keras model on the dataset\n",
    "history = model.fit(X, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 107us/step\n",
      "Accuracy: 78.39\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, Y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model\n",
    "#plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "#import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross entropy loss')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot history\n",
    "plt.plot(history.history['loss'], label='binary cross entropy loss')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Cross entropy loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make probability predictions with the model\n",
    "predictions = model.predict(X)\n",
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Create another model (give it a different name) with a slightly different architecture, e.g. with a different number of neurons in the two hidden layers. Specify how many neurons in each layer. Add an extra hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first hidden layer has 12 nodes and uses the relu activation function.\n",
      "The second hidden layer has 10 nodes and uses the relu activation function.\n",
      "The third hidden layer has 8 nodes and uses the relu activation function.\n",
      "The output layer has one node and uses the sigmoid activation function.\n"
     ]
    }
   ],
   "source": [
    "#Please post your solution here.\n",
    "#Feel free to add markdown and code cells as you need\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "tffun = 'relu'\n",
    "\n",
    "print('The first hidden layer has 12 nodes and uses the relu activation function.')\n",
    "print('The second hidden layer has 10 nodes and uses the relu activation function.')\n",
    "print('The third hidden layer has 8 nodes and uses the relu activation function.')\n",
    "print('The output layer has one node and uses the sigmoid activation function.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Split the data into a training set (80%) and a validation set (20%), by setting the *validation_split* parameter appropriately in the Keras model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please post your solution here.\n",
    "#Feel free to add markdown and code cells as you need\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X,Y, verbose = 0,\n",
    "                    validation_split = 0.2, # split data in 80-20 sets\n",
    "                    epochs = 150,\n",
    "                    batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 \n",
    "\n",
    "Visualize the performance of your model during training by using the history dictionary object (part of model.fit()). Plot training loss and validation loss against Epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4799 - accuracy: 0.7671 - val_loss: 0.4919 - val_accuracy: 0.7597\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4891 - accuracy: 0.7606 - val_loss: 0.4779 - val_accuracy: 0.7727\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4736 - accuracy: 0.7736 - val_loss: 0.5144 - val_accuracy: 0.7468\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4835 - accuracy: 0.7671 - val_loss: 0.4759 - val_accuracy: 0.7532\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4665 - accuracy: 0.7964 - val_loss: 0.4604 - val_accuracy: 0.7857\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4697 - accuracy: 0.7752 - val_loss: 0.4872 - val_accuracy: 0.7273\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4541 - accuracy: 0.7834 - val_loss: 0.4685 - val_accuracy: 0.7727\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4603 - accuracy: 0.7899 - val_loss: 0.4727 - val_accuracy: 0.7532\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4589 - accuracy: 0.7883 - val_loss: 0.4799 - val_accuracy: 0.7403\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4806 - accuracy: 0.7736 - val_loss: 0.4819 - val_accuracy: 0.7857\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4806 - accuracy: 0.7638 - val_loss: 0.4771 - val_accuracy: 0.7597\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4691 - accuracy: 0.7704 - val_loss: 0.4781 - val_accuracy: 0.7662\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4599 - accuracy: 0.7818 - val_loss: 0.5066 - val_accuracy: 0.7532\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4775 - accuracy: 0.7818 - val_loss: 0.4664 - val_accuracy: 0.7792\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.4594 - accuracy: 0.7752 - val_loss: 0.4775 - val_accuracy: 0.7792\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4545 - accuracy: 0.7834 - val_loss: 0.4697 - val_accuracy: 0.7792\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4500 - accuracy: 0.7785 - val_loss: 0.4991 - val_accuracy: 0.7403\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4532 - accuracy: 0.7964 - val_loss: 0.4892 - val_accuracy: 0.7532\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4530 - accuracy: 0.7866 - val_loss: 0.4760 - val_accuracy: 0.7532\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.4490 - accuracy: 0.7752 - val_loss: 0.4917 - val_accuracy: 0.7468\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4602 - accuracy: 0.7769 - val_loss: 0.4728 - val_accuracy: 0.7662\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4493 - accuracy: 0.7801 - val_loss: 0.4831 - val_accuracy: 0.7597\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.4491 - accuracy: 0.7769 - val_loss: 0.5543 - val_accuracy: 0.7273\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4543 - accuracy: 0.7866 - val_loss: 0.4856 - val_accuracy: 0.7662\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4597 - accuracy: 0.7834 - val_loss: 0.5137 - val_accuracy: 0.7208\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4595 - accuracy: 0.7834 - val_loss: 0.4929 - val_accuracy: 0.7597\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4579 - accuracy: 0.7801 - val_loss: 0.5140 - val_accuracy: 0.7727\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4466 - accuracy: 0.7915 - val_loss: 0.5187 - val_accuracy: 0.7338\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4491 - accuracy: 0.7866 - val_loss: 0.5205 - val_accuracy: 0.7532\n",
      "Epoch 30/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4650 - accuracy: 0.7818 - val_loss: 0.4745 - val_accuracy: 0.7857\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4459 - accuracy: 0.7850 - val_loss: 0.4773 - val_accuracy: 0.7662\n",
      "Epoch 32/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4512 - accuracy: 0.7720 - val_loss: 0.5116 - val_accuracy: 0.7078\n",
      "Epoch 33/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4539 - accuracy: 0.7915 - val_loss: 0.4823 - val_accuracy: 0.7727\n",
      "Epoch 34/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4579 - accuracy: 0.7834 - val_loss: 0.4720 - val_accuracy: 0.7662\n",
      "Epoch 35/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4400 - accuracy: 0.7948 - val_loss: 0.4742 - val_accuracy: 0.7727\n",
      "Epoch 36/150\n",
      "614/614 [==============================] - 0s 169us/step - loss: 0.4536 - accuracy: 0.7785 - val_loss: 0.4992 - val_accuracy: 0.7403\n",
      "Epoch 37/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4554 - accuracy: 0.7769 - val_loss: 0.4814 - val_accuracy: 0.7532\n",
      "Epoch 38/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4444 - accuracy: 0.7720 - val_loss: 0.4924 - val_accuracy: 0.7532\n",
      "Epoch 39/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4541 - accuracy: 0.7883 - val_loss: 0.4801 - val_accuracy: 0.7727\n",
      "Epoch 40/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4551 - accuracy: 0.7818 - val_loss: 0.4979 - val_accuracy: 0.7468\n",
      "Epoch 41/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.4493 - accuracy: 0.7997 - val_loss: 0.4904 - val_accuracy: 0.7727\n",
      "Epoch 42/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4744 - accuracy: 0.7850 - val_loss: 0.5423 - val_accuracy: 0.7532\n",
      "Epoch 43/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4624 - accuracy: 0.7752 - val_loss: 0.4858 - val_accuracy: 0.7727\n",
      "Epoch 44/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4534 - accuracy: 0.7899 - val_loss: 0.5246 - val_accuracy: 0.7403\n",
      "Epoch 45/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4564 - accuracy: 0.7720 - val_loss: 0.5487 - val_accuracy: 0.7662\n",
      "Epoch 46/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4642 - accuracy: 0.7834 - val_loss: 0.4878 - val_accuracy: 0.7857\n",
      "Epoch 47/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4535 - accuracy: 0.7785 - val_loss: 0.4792 - val_accuracy: 0.7597\n",
      "Epoch 48/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4470 - accuracy: 0.7834 - val_loss: 0.4757 - val_accuracy: 0.7727\n",
      "Epoch 49/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.4501 - accuracy: 0.7850 - val_loss: 0.4698 - val_accuracy: 0.7922\n",
      "Epoch 50/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4411 - accuracy: 0.7964 - val_loss: 0.4892 - val_accuracy: 0.7532\n",
      "Epoch 51/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4348 - accuracy: 0.7883 - val_loss: 0.5010 - val_accuracy: 0.7532\n",
      "Epoch 52/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4510 - accuracy: 0.7834 - val_loss: 0.5191 - val_accuracy: 0.7208\n",
      "Epoch 53/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4585 - accuracy: 0.7655 - val_loss: 0.4901 - val_accuracy: 0.7792\n",
      "Epoch 54/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.4436 - accuracy: 0.7932 - val_loss: 0.4934 - val_accuracy: 0.7597\n",
      "Epoch 55/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4483 - accuracy: 0.7883 - val_loss: 0.4955 - val_accuracy: 0.7727\n",
      "Epoch 56/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4446 - accuracy: 0.7915 - val_loss: 0.4827 - val_accuracy: 0.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4499 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7727\n",
      "Epoch 58/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4437 - accuracy: 0.7801 - val_loss: 0.4889 - val_accuracy: 0.7727\n",
      "Epoch 59/150\n",
      "614/614 [==============================] - 0s 157us/step - loss: 0.4477 - accuracy: 0.7769 - val_loss: 0.4943 - val_accuracy: 0.7597\n",
      "Epoch 60/150\n",
      "614/614 [==============================] - 0s 157us/step - loss: 0.4385 - accuracy: 0.7866 - val_loss: 0.4813 - val_accuracy: 0.7792\n",
      "Epoch 61/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4415 - accuracy: 0.8013 - val_loss: 0.4963 - val_accuracy: 0.7532\n",
      "Epoch 62/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4561 - accuracy: 0.7752 - val_loss: 0.5302 - val_accuracy: 0.7078\n",
      "Epoch 63/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4376 - accuracy: 0.7948 - val_loss: 0.4880 - val_accuracy: 0.7597\n",
      "Epoch 64/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4442 - accuracy: 0.7932 - val_loss: 0.5115 - val_accuracy: 0.7597\n",
      "Epoch 65/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4465 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7662\n",
      "Epoch 66/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4361 - accuracy: 0.7883 - val_loss: 0.5251 - val_accuracy: 0.7662\n",
      "Epoch 67/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4391 - accuracy: 0.7948 - val_loss: 0.4888 - val_accuracy: 0.7727\n",
      "Epoch 68/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4326 - accuracy: 0.8013 - val_loss: 0.4888 - val_accuracy: 0.7922\n",
      "Epoch 69/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4373 - accuracy: 0.7883 - val_loss: 0.5000 - val_accuracy: 0.7727\n",
      "Epoch 70/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4441 - accuracy: 0.7883 - val_loss: 0.5093 - val_accuracy: 0.7597\n",
      "Epoch 71/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4400 - accuracy: 0.7818 - val_loss: 0.4804 - val_accuracy: 0.7792\n",
      "Epoch 72/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4355 - accuracy: 0.7915 - val_loss: 0.4909 - val_accuracy: 0.7727\n",
      "Epoch 73/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4351 - accuracy: 0.7899 - val_loss: 0.5157 - val_accuracy: 0.7013\n",
      "Epoch 74/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4498 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7468\n",
      "Epoch 75/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4388 - accuracy: 0.8029 - val_loss: 0.5029 - val_accuracy: 0.7727\n",
      "Epoch 76/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4406 - accuracy: 0.7915 - val_loss: 0.5024 - val_accuracy: 0.7532\n",
      "Epoch 77/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4658 - accuracy: 0.7671 - val_loss: 0.5089 - val_accuracy: 0.7468\n",
      "Epoch 78/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4338 - accuracy: 0.7932 - val_loss: 0.4741 - val_accuracy: 0.7727\n",
      "Epoch 79/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4411 - accuracy: 0.7866 - val_loss: 0.4927 - val_accuracy: 0.7532\n",
      "Epoch 80/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4332 - accuracy: 0.7915 - val_loss: 0.5015 - val_accuracy: 0.7662\n",
      "Epoch 81/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4365 - accuracy: 0.8062 - val_loss: 0.4866 - val_accuracy: 0.7922\n",
      "Epoch 82/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4606 - accuracy: 0.7785 - val_loss: 0.4926 - val_accuracy: 0.7857\n",
      "Epoch 83/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4379 - accuracy: 0.7818 - val_loss: 0.5383 - val_accuracy: 0.7143\n",
      "Epoch 84/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4616 - accuracy: 0.7720 - val_loss: 0.4849 - val_accuracy: 0.7857\n",
      "Epoch 85/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4329 - accuracy: 0.7948 - val_loss: 0.4927 - val_accuracy: 0.7597\n",
      "Epoch 86/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4309 - accuracy: 0.7997 - val_loss: 0.5074 - val_accuracy: 0.7727\n",
      "Epoch 87/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4390 - accuracy: 0.7915 - val_loss: 0.5077 - val_accuracy: 0.7792\n",
      "Epoch 88/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4410 - accuracy: 0.7964 - val_loss: 0.4819 - val_accuracy: 0.7727\n",
      "Epoch 89/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4392 - accuracy: 0.7997 - val_loss: 0.4817 - val_accuracy: 0.7922\n",
      "Epoch 90/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4345 - accuracy: 0.7980 - val_loss: 0.4932 - val_accuracy: 0.7857\n",
      "Epoch 91/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4470 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7727\n",
      "Epoch 92/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4352 - accuracy: 0.8046 - val_loss: 0.5032 - val_accuracy: 0.7597\n",
      "Epoch 93/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4417 - accuracy: 0.7736 - val_loss: 0.5032 - val_accuracy: 0.7597\n",
      "Epoch 94/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4403 - accuracy: 0.7883 - val_loss: 0.4853 - val_accuracy: 0.7727\n",
      "Epoch 95/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4384 - accuracy: 0.7915 - val_loss: 0.5203 - val_accuracy: 0.7792\n",
      "Epoch 96/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4345 - accuracy: 0.7883 - val_loss: 0.4895 - val_accuracy: 0.7922\n",
      "Epoch 97/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4360 - accuracy: 0.7850 - val_loss: 0.4915 - val_accuracy: 0.7922\n",
      "Epoch 98/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4392 - accuracy: 0.8013 - val_loss: 0.5141 - val_accuracy: 0.7662\n",
      "Epoch 99/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4358 - accuracy: 0.7948 - val_loss: 0.4964 - val_accuracy: 0.7727\n",
      "Epoch 100/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4356 - accuracy: 0.7997 - val_loss: 0.4953 - val_accuracy: 0.7662\n",
      "Epoch 101/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4348 - accuracy: 0.7801 - val_loss: 0.5180 - val_accuracy: 0.7532\n",
      "Epoch 102/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4303 - accuracy: 0.7932 - val_loss: 0.4917 - val_accuracy: 0.7597\n",
      "Epoch 103/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4295 - accuracy: 0.7980 - val_loss: 0.5062 - val_accuracy: 0.7468\n",
      "Epoch 104/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4274 - accuracy: 0.8046 - val_loss: 0.5026 - val_accuracy: 0.7792\n",
      "Epoch 105/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4350 - accuracy: 0.7964 - val_loss: 0.4952 - val_accuracy: 0.7987\n",
      "Epoch 106/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4352 - accuracy: 0.7915 - val_loss: 0.5087 - val_accuracy: 0.7792\n",
      "Epoch 107/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4286 - accuracy: 0.7997 - val_loss: 0.5190 - val_accuracy: 0.7662\n",
      "Epoch 108/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4388 - accuracy: 0.7915 - val_loss: 0.4965 - val_accuracy: 0.7662\n",
      "Epoch 109/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4423 - accuracy: 0.8029 - val_loss: 0.5103 - val_accuracy: 0.7468\n",
      "Epoch 110/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4231 - accuracy: 0.8013 - val_loss: 0.4938 - val_accuracy: 0.7662\n",
      "Epoch 111/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4296 - accuracy: 0.7997 - val_loss: 0.4820 - val_accuracy: 0.7922\n",
      "Epoch 112/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4333 - accuracy: 0.7997 - val_loss: 0.5167 - val_accuracy: 0.7792\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 162us/step - loss: 0.4234 - accuracy: 0.8111 - val_loss: 0.5015 - val_accuracy: 0.7727\n",
      "Epoch 114/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4230 - accuracy: 0.7850 - val_loss: 0.5072 - val_accuracy: 0.7468\n",
      "Epoch 115/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4321 - accuracy: 0.7866 - val_loss: 0.4885 - val_accuracy: 0.7987\n",
      "Epoch 116/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4181 - accuracy: 0.8094 - val_loss: 0.5500 - val_accuracy: 0.7532\n",
      "Epoch 117/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4322 - accuracy: 0.7866 - val_loss: 0.4808 - val_accuracy: 0.7987\n",
      "Epoch 118/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4316 - accuracy: 0.7948 - val_loss: 0.5139 - val_accuracy: 0.7727\n",
      "Epoch 119/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4286 - accuracy: 0.8046 - val_loss: 0.5101 - val_accuracy: 0.7662\n",
      "Epoch 120/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4273 - accuracy: 0.8013 - val_loss: 0.5256 - val_accuracy: 0.7468\n",
      "Epoch 121/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4270 - accuracy: 0.8062 - val_loss: 0.4884 - val_accuracy: 0.7792\n",
      "Epoch 122/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4210 - accuracy: 0.8029 - val_loss: 0.5078 - val_accuracy: 0.7597\n",
      "Epoch 123/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4236 - accuracy: 0.8143 - val_loss: 0.5088 - val_accuracy: 0.7727\n",
      "Epoch 124/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4287 - accuracy: 0.7980 - val_loss: 0.5052 - val_accuracy: 0.7532\n",
      "Epoch 125/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4180 - accuracy: 0.8143 - val_loss: 0.5090 - val_accuracy: 0.7727\n",
      "Epoch 126/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4259 - accuracy: 0.8094 - val_loss: 0.5183 - val_accuracy: 0.7597\n",
      "Epoch 127/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4238 - accuracy: 0.8094 - val_loss: 0.5164 - val_accuracy: 0.7597\n",
      "Epoch 128/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4891 - val_accuracy: 0.7597\n",
      "Epoch 129/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4362 - accuracy: 0.8013 - val_loss: 0.4976 - val_accuracy: 0.7792\n",
      "Epoch 130/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4302 - accuracy: 0.8094 - val_loss: 0.4975 - val_accuracy: 0.7727\n",
      "Epoch 131/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4250 - accuracy: 0.8013 - val_loss: 0.4926 - val_accuracy: 0.7792\n",
      "Epoch 132/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4311 - accuracy: 0.7883 - val_loss: 0.5115 - val_accuracy: 0.7597\n",
      "Epoch 133/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4285 - accuracy: 0.8013 - val_loss: 0.4940 - val_accuracy: 0.7857\n",
      "Epoch 134/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4237 - accuracy: 0.7980 - val_loss: 0.5195 - val_accuracy: 0.7597\n",
      "Epoch 135/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4483 - accuracy: 0.7818 - val_loss: 0.4974 - val_accuracy: 0.7987\n",
      "Epoch 136/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4185 - accuracy: 0.7997 - val_loss: 0.4993 - val_accuracy: 0.7403\n",
      "Epoch 137/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4174 - accuracy: 0.8013 - val_loss: 0.5173 - val_accuracy: 0.7597\n",
      "Epoch 138/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4235 - accuracy: 0.8062 - val_loss: 0.5088 - val_accuracy: 0.7403\n",
      "Epoch 139/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4377 - accuracy: 0.7932 - val_loss: 0.4972 - val_accuracy: 0.7597\n",
      "Epoch 140/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4385 - accuracy: 0.7948 - val_loss: 0.4957 - val_accuracy: 0.7857\n",
      "Epoch 141/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4258 - accuracy: 0.7915 - val_loss: 0.5221 - val_accuracy: 0.7403\n",
      "Epoch 142/150\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4309 - accuracy: 0.8013 - val_loss: 0.5477 - val_accuracy: 0.7338\n",
      "Epoch 143/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4261 - accuracy: 0.8046 - val_loss: 0.4997 - val_accuracy: 0.7532\n",
      "Epoch 144/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4156 - accuracy: 0.8013 - val_loss: 0.4888 - val_accuracy: 0.7727\n",
      "Epoch 145/150\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.4281 - accuracy: 0.8046 - val_loss: 0.4988 - val_accuracy: 0.7532\n",
      "Epoch 146/150\n",
      "614/614 [==============================] - 0s 166us/step - loss: 0.4290 - accuracy: 0.7915 - val_loss: 0.5002 - val_accuracy: 0.7662\n",
      "Epoch 147/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.4232 - accuracy: 0.7997 - val_loss: 0.5027 - val_accuracy: 0.7403\n",
      "Epoch 148/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4291 - accuracy: 0.8078 - val_loss: 0.5032 - val_accuracy: 0.7857\n",
      "Epoch 149/150\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.4161 - accuracy: 0.7964 - val_loss: 0.4950 - val_accuracy: 0.7792\n",
      "Epoch 150/150\n",
      "614/614 [==============================] - 0s 165us/step - loss: 0.4226 - accuracy: 0.7964 - val_loss: 0.4934 - val_accuracy: 0.7922\n"
     ]
    }
   ],
   "source": [
    "#Please post your solution here.\n",
    "#Feel free to add markdown and code cells as you need\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(0,150)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "\n",
    "Using your model from *Task 1* change the activation functions and see how this affects training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please post your solution here.\n",
    "#Feel free to add markdown and code cells as you need\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='selu'))\n",
    "model.add(Dense(10, activation='selu'))\n",
    "model.add(Dense(8, activation='selu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "tfo = 'selu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 959us/step - loss: 13.6145 - accuracy: 0.3698\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.9578 - accuracy: 0.6667\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 174us/step - loss: 0.7094 - accuracy: 0.6693\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6703 - accuracy: 0.6680\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.6428 - accuracy: 0.6732\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.6251 - accuracy: 0.6836\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.6114 - accuracy: 0.6875\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 188us/step - loss: 0.5984 - accuracy: 0.6992\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5833 - accuracy: 0.7083\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 179us/step - loss: 0.5748 - accuracy: 0.7044\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 188us/step - loss: 0.5646 - accuracy: 0.7096\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 188us/step - loss: 0.5616 - accuracy: 0.7161\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.5546 - accuracy: 0.7148\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.5473 - accuracy: 0.7057\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.5432 - accuracy: 0.7266\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5432 - accuracy: 0.7253\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.5348 - accuracy: 0.7214\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 179us/step - loss: 0.5298 - accuracy: 0.7357\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.5322 - accuracy: 0.7357\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 465us/step - loss: 0.5327 - accuracy: 0.7383\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 1s 653us/step - loss: 0.5263 - accuracy: 0.7266\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.5230 - accuracy: 0.7305\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.5237 - accuracy: 0.7357\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.5171 - accuracy: 0.7383\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.5110 - accuracy: 0.7331\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.5105 - accuracy: 0.7461\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.5149 - accuracy: 0.7370\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5089 - accuracy: 0.7357\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.5201 - accuracy: 0.7487\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.5117 - accuracy: 0.7487\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.7578\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4968 - accuracy: 0.7617\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.5058 - accuracy: 0.7435\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4947 - accuracy: 0.7552\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4998 - accuracy: 0.7513\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4984 - accuracy: 0.7500\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4989 - accuracy: 0.7474\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4943 - accuracy: 0.7513\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4850 - accuracy: 0.7617\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4818 - accuracy: 0.7656\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 419us/step - loss: 0.4784 - accuracy: 0.7630\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 567us/step - loss: 0.4853 - accuracy: 0.7591\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 1s 853us/step - loss: 0.4802 - accuracy: 0.7578\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 1s 925us/step - loss: 0.4769 - accuracy: 0.7591\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 1s 877us/step - loss: 0.4752 - accuracy: 0.7695\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 1s 931us/step - loss: 0.4850 - accuracy: 0.7643\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.7708\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4768 - accuracy: 0.7591\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4700 - accuracy: 0.7773\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4789 - accuracy: 0.7734\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4747 - accuracy: 0.7695\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4716 - accuracy: 0.7669\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4738 - accuracy: 0.7734\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4733 - accuracy: 0.7669\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4691 - accuracy: 0.7604\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4805 - accuracy: 0.7565\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 415us/step - loss: 0.4690 - accuracy: 0.7695\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 594us/step - loss: 0.4752 - accuracy: 0.7578\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 1s 755us/step - loss: 0.4693 - accuracy: 0.7682\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 1s 820us/step - loss: 0.4799 - accuracy: 0.7656\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4703 - accuracy: 0.7630\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4783 - accuracy: 0.7682\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4723 - accuracy: 0.7669\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7734\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4643 - accuracy: 0.7760\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4738 - accuracy: 0.7682\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.7734\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4609 - accuracy: 0.7721\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4731 - accuracy: 0.7617\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.4758 - accuracy: 0.7669\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 1s 693us/step - loss: 0.4700 - accuracy: 0.7604\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4653 - accuracy: 0.7695\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4732 - accuracy: 0.7734\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.7695\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7643\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.7682\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4643 - accuracy: 0.7656\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4708 - accuracy: 0.7656\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4646 - accuracy: 0.7656\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4677 - accuracy: 0.7682\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4658 - accuracy: 0.7695\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4636 - accuracy: 0.7760\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4624 - accuracy: 0.7734\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4631 - accuracy: 0.7669\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4680 - accuracy: 0.7708\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 3s 5ms/step - loss: 0.4655 - accuracy: 0.7591\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4589 - accuracy: 0.7747\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4588 - accuracy: 0.7630\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4753 - accuracy: 0.7643\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4797 - accuracy: 0.7539\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4717 - accuracy: 0.7656\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4619 - accuracy: 0.7708\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4670 - accuracy: 0.7578\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4629 - accuracy: 0.7760\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4572 - accuracy: 0.7721\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4583 - accuracy: 0.7812\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4690 - accuracy: 0.7734\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 3s 5ms/step - loss: 0.4620 - accuracy: 0.7721\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4618 - accuracy: 0.7734\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4602 - accuracy: 0.7799\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4614 - accuracy: 0.7747\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4687 - accuracy: 0.7747\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4655 - accuracy: 0.7708\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 481us/step - loss: 0.4602 - accuracy: 0.7773\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 1s 793us/step - loss: 0.4659 - accuracy: 0.7669\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4585 - accuracy: 0.7760\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4608 - accuracy: 0.7682\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4584 - accuracy: 0.7682\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4567 - accuracy: 0.7734\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4547 - accuracy: 0.7786\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 628us/step - loss: 0.4749 - accuracy: 0.7747\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4732 - accuracy: 0.7721\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 603us/step - loss: 0.4602 - accuracy: 0.7630\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 646us/step - loss: 0.4549 - accuracy: 0.7708\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4687 - accuracy: 0.7656\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4637 - accuracy: 0.7656\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4618 - accuracy: 0.7682\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4529 - accuracy: 0.7878\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4626 - accuracy: 0.7747\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4534 - accuracy: 0.7721\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4598 - accuracy: 0.7669\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4578 - accuracy: 0.7839\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4651 - accuracy: 0.7747\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4569 - accuracy: 0.7708\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4567 - accuracy: 0.7734\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4569 - accuracy: 0.7799\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4528 - accuracy: 0.7747\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4555 - accuracy: 0.7786\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4594 - accuracy: 0.7773\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4551 - accuracy: 0.7852\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4510 - accuracy: 0.7799\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4570 - accuracy: 0.7747\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4527 - accuracy: 0.7734\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4499 - accuracy: 0.7812\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4604 - accuracy: 0.7760\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4553 - accuracy: 0.7773\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4790 - accuracy: 0.7721\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4581 - accuracy: 0.7799\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4630 - accuracy: 0.7682\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4524 - accuracy: 0.7773\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4600 - accuracy: 0.7682\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 611us/step - loss: 0.4507 - accuracy: 0.7826\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4612 - accuracy: 0.7721\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 437us/step - loss: 0.4560 - accuracy: 0.7734\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 1s 763us/step - loss: 0.4496 - accuracy: 0.7865\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4506 - accuracy: 0.7812\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4517 - accuracy: 0.7812\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.7773\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4505 - accuracy: 0.7799\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4526 - accuracy: 0.7878\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, Y, epochs=150, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 151us/step\n",
      "Accuracy: 78.26\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, Y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "b = accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After changing the activation there is no much change in the accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "\n",
    "Increase the number of epochs. See what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4568 - accuracy: 0.7721\n",
      "Epoch 2/250\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.4521 - accuracy: 0.7708\n",
      "Epoch 3/250\n",
      "768/768 [==============================] - 0s 174us/step - loss: 0.4544 - accuracy: 0.7747\n",
      "Epoch 4/250\n",
      "768/768 [==============================] - 0s 176us/step - loss: 0.4473 - accuracy: 0.7852\n",
      "Epoch 5/250\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.4605 - accuracy: 0.7734\n",
      "Epoch 6/250\n",
      "768/768 [==============================] - 0s 176us/step - loss: 0.4474 - accuracy: 0.7747\n",
      "Epoch 7/250\n",
      "768/768 [==============================] - 0s 176us/step - loss: 0.4492 - accuracy: 0.7773\n",
      "Epoch 8/250\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.4489 - accuracy: 0.7747\n",
      "Epoch 9/250\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.4520 - accuracy: 0.7852\n",
      "Epoch 10/250\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.4545 - accuracy: 0.7812\n",
      "Epoch 11/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4600 - accuracy: 0.7799\n",
      "Epoch 12/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4519 - accuracy: 0.7721\n",
      "Epoch 13/250\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.4514 - accuracy: 0.7747\n",
      "Epoch 14/250\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4553 - accuracy: 0.7708\n",
      "Epoch 15/250\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4491 - accuracy: 0.7760\n",
      "Epoch 16/250\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4506 - accuracy: 0.7773\n",
      "Epoch 17/250\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.4459 - accuracy: 0.7799\n",
      "Epoch 18/250\n",
      "768/768 [==============================] - 0s 184us/step - loss: 0.4544 - accuracy: 0.7760\n",
      "Epoch 19/250\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.4506 - accuracy: 0.7826\n",
      "Epoch 20/250\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.4482 - accuracy: 0.7878\n",
      "Epoch 21/250\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.4474 - accuracy: 0.7852\n",
      "Epoch 22/250\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.4566 - accuracy: 0.7682\n",
      "Epoch 23/250\n",
      "768/768 [==============================] - 1s 697us/step - loss: 0.4515 - accuracy: 0.7734\n",
      "Epoch 24/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4571 - accuracy: 0.7747\n",
      "Epoch 25/250\n",
      "768/768 [==============================] - 1s 901us/step - loss: 0.4536 - accuracy: 0.7878\n",
      "Epoch 26/250\n",
      "768/768 [==============================] - 0s 440us/step - loss: 0.4490 - accuracy: 0.7760\n",
      "Epoch 27/250\n",
      "768/768 [==============================] - 0s 521us/step - loss: 0.4473 - accuracy: 0.7839\n",
      "Epoch 28/250\n",
      "768/768 [==============================] - 0s 623us/step - loss: 0.4437 - accuracy: 0.7865\n",
      "Epoch 29/250\n",
      "768/768 [==============================] - 1s 758us/step - loss: 0.4513 - accuracy: 0.7786\n",
      "Epoch 30/250\n",
      "768/768 [==============================] - 1s 782us/step - loss: 0.4553 - accuracy: 0.7760\n",
      "Epoch 31/250\n",
      "768/768 [==============================] - 1s 846us/step - loss: 0.4486 - accuracy: 0.7812\n",
      "Epoch 32/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4726 - accuracy: 0.7799\n",
      "Epoch 33/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4559 - accuracy: 0.7747\n",
      "Epoch 34/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4773 - accuracy: 0.7695\n",
      "Epoch 35/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4593 - accuracy: 0.7812\n",
      "Epoch 36/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4516 - accuracy: 0.7878\n",
      "Epoch 37/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4657 - accuracy: 0.7656\n",
      "Epoch 38/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4587 - accuracy: 0.7826\n",
      "Epoch 39/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4476 - accuracy: 0.7734\n",
      "Epoch 40/250\n",
      "768/768 [==============================] - 0s 447us/step - loss: 0.4553 - accuracy: 0.7760\n",
      "Epoch 41/250\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.4483 - accuracy: 0.7826\n",
      "Epoch 42/250\n",
      "768/768 [==============================] - 0s 477us/step - loss: 0.4486 - accuracy: 0.7839\n",
      "Epoch 43/250\n",
      "768/768 [==============================] - 0s 599us/step - loss: 0.4489 - accuracy: 0.7826\n",
      "Epoch 44/250\n",
      "768/768 [==============================] - 0s 593us/step - loss: 0.4483 - accuracy: 0.7773\n",
      "Epoch 45/250\n",
      "768/768 [==============================] - 1s 748us/step - loss: 0.4521 - accuracy: 0.7852\n",
      "Epoch 46/250\n",
      "768/768 [==============================] - 1s 898us/step - loss: 0.4433 - accuracy: 0.7812\n",
      "Epoch 47/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4479 - accuracy: 0.7799\n",
      "Epoch 48/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4456 - accuracy: 0.7708\n",
      "Epoch 49/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4479 - accuracy: 0.7878\n",
      "Epoch 50/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4475 - accuracy: 0.7799\n",
      "Epoch 51/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4513 - accuracy: 0.7812\n",
      "Epoch 52/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4614 - accuracy: 0.7682\n",
      "Epoch 53/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.7865\n",
      "Epoch 54/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.7852\n",
      "Epoch 55/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4460 - accuracy: 0.7826\n",
      "Epoch 56/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.7891\n",
      "Epoch 57/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4536 - accuracy: 0.7708\n",
      "Epoch 58/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4461 - accuracy: 0.7799\n",
      "Epoch 59/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4489 - accuracy: 0.7799\n",
      "Epoch 60/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4467 - accuracy: 0.7839\n",
      "Epoch 61/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4407 - accuracy: 0.7852\n",
      "Epoch 62/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4427 - accuracy: 0.7865\n",
      "Epoch 63/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4427 - accuracy: 0.7786\n",
      "Epoch 64/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4427 - accuracy: 0.7760\n",
      "Epoch 65/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4514 - accuracy: 0.7839\n",
      "Epoch 66/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.7760\n",
      "Epoch 67/250\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.4604 - accuracy: 0.7839\n",
      "Epoch 68/250\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.4519 - accuracy: 0.7734\n",
      "Epoch 69/250\n",
      "768/768 [==============================] - 0s 509us/step - loss: 0.4451 - accuracy: 0.7826\n",
      "Epoch 70/250\n",
      "768/768 [==============================] - 0s 597us/step - loss: 0.4484 - accuracy: 0.7812\n",
      "Epoch 71/250\n",
      "768/768 [==============================] - 1s 772us/step - loss: 0.4457 - accuracy: 0.7865\n",
      "Epoch 72/250\n",
      "768/768 [==============================] - 1s 960us/step - loss: 0.4458 - accuracy: 0.7812\n",
      "Epoch 73/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4434 - accuracy: 0.7839\n",
      "Epoch 74/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4502 - accuracy: 0.7839\n",
      "Epoch 75/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4435 - accuracy: 0.7865\n",
      "Epoch 76/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4425 - accuracy: 0.7878\n",
      "Epoch 77/250\n",
      "768/768 [==============================] - 1s 876us/step - loss: 0.4475 - accuracy: 0.7865\n",
      "Epoch 78/250\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.4452 - accuracy: 0.7865\n",
      "Epoch 79/250\n",
      "768/768 [==============================] - 0s 363us/step - loss: 0.4541 - accuracy: 0.7852\n",
      "Epoch 80/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 401us/step - loss: 0.4405 - accuracy: 0.7839\n",
      "Epoch 81/250\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.4407 - accuracy: 0.7904\n",
      "Epoch 82/250\n",
      "768/768 [==============================] - 0s 587us/step - loss: 0.4458 - accuracy: 0.7760\n",
      "Epoch 83/250\n",
      "768/768 [==============================] - 0s 466us/step - loss: 0.4438 - accuracy: 0.7799\n",
      "Epoch 84/250\n",
      "768/768 [==============================] - 1s 908us/step - loss: 0.4425 - accuracy: 0.7891\n",
      "Epoch 85/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.7839\n",
      "Epoch 86/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.7852\n",
      "Epoch 87/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4398 - accuracy: 0.7852\n",
      "Epoch 88/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4497 - accuracy: 0.7786\n",
      "Epoch 89/250\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4423 - accuracy: 0.7852\n",
      "Epoch 90/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4445 - accuracy: 0.7799\n",
      "Epoch 91/250\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.4413 - accuracy: 0.7799\n",
      "Epoch 92/250\n",
      "768/768 [==============================] - 0s 414us/step - loss: 0.4466 - accuracy: 0.7786\n",
      "Epoch 93/250\n",
      "768/768 [==============================] - 0s 538us/step - loss: 0.4433 - accuracy: 0.7799\n",
      "Epoch 94/250\n",
      "768/768 [==============================] - 0s 631us/step - loss: 0.4490 - accuracy: 0.7839\n",
      "Epoch 95/250\n",
      "768/768 [==============================] - 1s 705us/step - loss: 0.4402 - accuracy: 0.7826\n",
      "Epoch 96/250\n",
      "768/768 [==============================] - 1s 793us/step - loss: 0.4392 - accuracy: 0.7839\n",
      "Epoch 97/250\n",
      "768/768 [==============================] - 1s 863us/step - loss: 0.4405 - accuracy: 0.7812\n",
      "Epoch 98/250\n",
      "768/768 [==============================] - 1s 704us/step - loss: 0.4370 - accuracy: 0.7917\n",
      "Epoch 99/250\n",
      "768/768 [==============================] - 1s 856us/step - loss: 0.4504 - accuracy: 0.7760\n",
      "Epoch 100/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4396 - accuracy: 0.7786\n",
      "Epoch 101/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4428 - accuracy: 0.7930\n",
      "Epoch 102/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4431 - accuracy: 0.7799\n",
      "Epoch 103/250\n",
      "768/768 [==============================] - 0s 360us/step - loss: 0.4397 - accuracy: 0.7852\n",
      "Epoch 104/250\n",
      "768/768 [==============================] - 0s 478us/step - loss: 0.4465 - accuracy: 0.7839\n",
      "Epoch 105/250\n",
      "768/768 [==============================] - 0s 549us/step - loss: 0.4393 - accuracy: 0.7852\n",
      "Epoch 106/250\n",
      "768/768 [==============================] - 1s 754us/step - loss: 0.4359 - accuracy: 0.7943\n",
      "Epoch 107/250\n",
      "768/768 [==============================] - 1s 793us/step - loss: 0.4435 - accuracy: 0.7930\n",
      "Epoch 108/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4438 - accuracy: 0.7812\n",
      "Epoch 109/250\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.4522 - accuracy: 0.7747\n",
      "Epoch 110/250\n",
      "768/768 [==============================] - 0s 382us/step - loss: 0.4436 - accuracy: 0.7852\n",
      "Epoch 111/250\n",
      "768/768 [==============================] - 0s 463us/step - loss: 0.4464 - accuracy: 0.7904\n",
      "Epoch 112/250\n",
      "768/768 [==============================] - 0s 630us/step - loss: 0.4498 - accuracy: 0.7734\n",
      "Epoch 113/250\n",
      "768/768 [==============================] - 1s 763us/step - loss: 0.4498 - accuracy: 0.7773\n",
      "Epoch 114/250\n",
      "768/768 [==============================] - 1s 756us/step - loss: 0.4404 - accuracy: 0.7826\n",
      "Epoch 115/250\n",
      "768/768 [==============================] - 1s 955us/step - loss: 0.4390 - accuracy: 0.7917\n",
      "Epoch 116/250\n",
      "768/768 [==============================] - 1s 979us/step - loss: 0.4464 - accuracy: 0.7786\n",
      "Epoch 117/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4355 - accuracy: 0.7799\n",
      "Epoch 118/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4500 - accuracy: 0.7786\n",
      "Epoch 119/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4384 - accuracy: 0.7878\n",
      "Epoch 120/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4467 - accuracy: 0.7708\n",
      "Epoch 121/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4345 - accuracy: 0.7969\n",
      "Epoch 122/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4595 - accuracy: 0.7721\n",
      "Epoch 123/250\n",
      "768/768 [==============================] - 3s 5ms/step - loss: 0.4390 - accuracy: 0.7969\n",
      "Epoch 124/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4478 - accuracy: 0.7721\n",
      "Epoch 125/250\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.4423 - accuracy: 0.7878\n",
      "Epoch 126/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4543 - accuracy: 0.7852\n",
      "Epoch 127/250\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4415 - accuracy: 0.7865\n",
      "Epoch 128/250\n",
      "768/768 [==============================] - 6s 8ms/step - loss: 0.4427 - accuracy: 0.7747\n",
      "Epoch 129/250\n",
      "768/768 [==============================] - 6s 8ms/step - loss: 0.4479 - accuracy: 0.7799\n",
      "Epoch 130/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4416 - accuracy: 0.7891\n",
      "Epoch 131/250\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4390 - accuracy: 0.7839\n",
      "Epoch 132/250\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.4367 - accuracy: 0.7865\n",
      "Epoch 133/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4462 - accuracy: 0.7773\n",
      "Epoch 134/250\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.4325 - accuracy: 0.7943\n",
      "Epoch 135/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4454 - accuracy: 0.7773\n",
      "Epoch 136/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4380 - accuracy: 0.7943\n",
      "Epoch 137/250\n",
      "768/768 [==============================] - 6s 8ms/step - loss: 0.4466 - accuracy: 0.7826\n",
      "Epoch 138/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.7786\n",
      "Epoch 139/250\n",
      "768/768 [==============================] - 1s 854us/step - loss: 0.4473 - accuracy: 0.7852\n",
      "Epoch 140/250\n",
      "768/768 [==============================] - 1s 983us/step - loss: 0.4433 - accuracy: 0.7891\n",
      "Epoch 141/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.7773\n",
      "Epoch 142/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4357 - accuracy: 0.7878\n",
      "Epoch 143/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4400 - accuracy: 0.7839\n",
      "Epoch 144/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4370 - accuracy: 0.7917\n",
      "Epoch 145/250\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4436 - accuracy: 0.7995\n",
      "Epoch 146/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4393 - accuracy: 0.7760\n",
      "Epoch 147/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4376 - accuracy: 0.7878\n",
      "Epoch 148/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4366 - accuracy: 0.7878\n",
      "Epoch 149/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4400 - accuracy: 0.7812\n",
      "Epoch 150/250\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4398 - accuracy: 0.7839\n",
      "Epoch 151/250\n",
      "768/768 [==============================] - 6s 8ms/step - loss: 0.4369 - accuracy: 0.7865\n",
      "Epoch 152/250\n",
      "768/768 [==============================] - 6s 8ms/step - loss: 0.4334 - accuracy: 0.7826\n",
      "Epoch 153/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4469 - accuracy: 0.7852\n",
      "Epoch 154/250\n",
      "768/768 [==============================] - 7s 10ms/step - loss: 0.4375 - accuracy: 0.7904\n",
      "Epoch 155/250\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.4435 - accuracy: 0.7865\n",
      "Epoch 156/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4408 - accuracy: 0.7786\n",
      "Epoch 157/250\n",
      "768/768 [==============================] - 9s 11ms/step - loss: 0.4374 - accuracy: 0.7865\n",
      "Epoch 158/250\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.4406 - accuracy: 0.7969\n",
      "Epoch 159/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 6s 7ms/step - loss: 0.4374 - accuracy: 0.7982\n",
      "Epoch 160/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4463 - accuracy: 0.7852\n",
      "Epoch 161/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.7773\n",
      "Epoch 162/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.7904\n",
      "Epoch 163/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4381 - accuracy: 0.8021\n",
      "Epoch 164/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4430 - accuracy: 0.7839\n",
      "Epoch 165/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4366 - accuracy: 0.7786\n",
      "Epoch 166/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4408 - accuracy: 0.7891\n",
      "Epoch 167/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4330 - accuracy: 0.7852\n",
      "Epoch 168/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4395 - accuracy: 0.7826\n",
      "Epoch 169/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4311 - accuracy: 0.7917\n",
      "Epoch 170/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4432 - accuracy: 0.7904\n",
      "Epoch 171/250\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4466 - accuracy: 0.7839\n",
      "Epoch 172/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4482 - accuracy: 0.7878\n",
      "Epoch 173/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4415 - accuracy: 0.7773\n",
      "Epoch 174/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4346 - accuracy: 0.7852\n",
      "Epoch 175/250\n",
      "768/768 [==============================] - 6s 8ms/step - loss: 0.4326 - accuracy: 0.7995\n",
      "Epoch 176/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4462 - accuracy: 0.7786\n",
      "Epoch 177/250\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.4367 - accuracy: 0.7878\n",
      "Epoch 178/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4283 - accuracy: 0.7930\n",
      "Epoch 179/250\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.4359 - accuracy: 0.7943\n",
      "Epoch 180/250\n",
      "768/768 [==============================] - 8s 11ms/step - loss: 0.4454 - accuracy: 0.7852\n",
      "Epoch 181/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4312 - accuracy: 0.7852\n",
      "Epoch 182/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.7773\n",
      "Epoch 183/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4289 - accuracy: 0.7891\n",
      "Epoch 184/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4319 - accuracy: 0.7969\n",
      "Epoch 185/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.7891\n",
      "Epoch 186/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.7865\n",
      "Epoch 187/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.7760\n",
      "Epoch 188/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4342 - accuracy: 0.7943\n",
      "Epoch 189/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4363 - accuracy: 0.7852\n",
      "Epoch 190/250\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4320 - accuracy: 0.7956\n",
      "Epoch 191/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4379 - accuracy: 0.7891\n",
      "Epoch 192/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4322 - accuracy: 0.7956\n",
      "Epoch 193/250\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4304 - accuracy: 0.7943\n",
      "Epoch 194/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4403 - accuracy: 0.7904\n",
      "Epoch 195/250\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4387 - accuracy: 0.7930\n",
      "Epoch 196/250\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4416 - accuracy: 0.7773\n",
      "Epoch 197/250\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4392 - accuracy: 0.7865\n",
      "Epoch 198/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4310 - accuracy: 0.7839\n",
      "Epoch 199/250\n",
      "768/768 [==============================] - 6s 8ms/step - loss: 0.4348 - accuracy: 0.7917\n",
      "Epoch 200/250\n",
      "768/768 [==============================] - 7s 8ms/step - loss: 0.4312 - accuracy: 0.7930\n",
      "Epoch 201/250\n",
      "768/768 [==============================] - 7s 10ms/step - loss: 0.4334 - accuracy: 0.7995\n",
      "Epoch 202/250\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.4316 - accuracy: 0.7969\n",
      "Epoch 203/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4414 - accuracy: 0.7995\n",
      "Epoch 204/250\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.4337 - accuracy: 0.7995\n",
      "Epoch 205/250\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.4309 - accuracy: 0.7878\n",
      "Epoch 206/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4424 - accuracy: 0.7865\n",
      "Epoch 207/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4319 - accuracy: 0.7891\n",
      "Epoch 208/250\n",
      "768/768 [==============================] - 1s 832us/step - loss: 0.4329 - accuracy: 0.7943\n",
      "Epoch 209/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4316 - accuracy: 0.8034\n",
      "Epoch 210/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4315 - accuracy: 0.7943\n",
      "Epoch 211/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4310 - accuracy: 0.7760\n",
      "Epoch 212/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4285 - accuracy: 0.7943\n",
      "Epoch 213/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4267 - accuracy: 0.8008\n",
      "Epoch 214/250\n",
      "768/768 [==============================] - 3s 3ms/step - loss: 0.4323 - accuracy: 0.7917\n",
      "Epoch 215/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4375 - accuracy: 0.8021\n",
      "Epoch 216/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4418 - accuracy: 0.7956\n",
      "Epoch 217/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4390 - accuracy: 0.7930\n",
      "Epoch 218/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4354 - accuracy: 0.7734\n",
      "Epoch 219/250\n",
      "768/768 [==============================] - 5s 6ms/step - loss: 0.4353 - accuracy: 0.7917\n",
      "Epoch 220/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4320 - accuracy: 0.7891\n",
      "Epoch 221/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4276 - accuracy: 0.7839\n",
      "Epoch 222/250\n",
      "768/768 [==============================] - 6s 8ms/step - loss: 0.4300 - accuracy: 0.7917\n",
      "Epoch 223/250\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4281 - accuracy: 0.7982\n",
      "Epoch 224/250\n",
      "768/768 [==============================] - 7s 10ms/step - loss: 0.4284 - accuracy: 0.7969\n",
      "Epoch 225/250\n",
      "768/768 [==============================] - 6s 7ms/step - loss: 0.4260 - accuracy: 0.7995\n",
      "Epoch 226/250\n",
      "768/768 [==============================] - 0s 593us/step - loss: 0.4404 - accuracy: 0.7943\n",
      "Epoch 227/250\n",
      "768/768 [==============================] - 1s 987us/step - loss: 0.4277 - accuracy: 0.7917\n",
      "Epoch 228/250\n",
      "768/768 [==============================] - 1s 952us/step - loss: 0.4300 - accuracy: 0.7956\n",
      "Epoch 229/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4296 - accuracy: 0.7930\n",
      "Epoch 230/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4339 - accuracy: 0.7969\n",
      "Epoch 231/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4295 - accuracy: 0.7891\n",
      "Epoch 232/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4289 - accuracy: 0.7865\n",
      "Epoch 233/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4284 - accuracy: 0.7982\n",
      "Epoch 234/250\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4457 - accuracy: 0.7891\n",
      "Epoch 235/250\n",
      "768/768 [==============================] - 1s 908us/step - loss: 0.4328 - accuracy: 0.7904\n",
      "Epoch 236/250\n",
      "768/768 [==============================] - 0s 513us/step - loss: 0.4334 - accuracy: 0.7982\n",
      "Epoch 237/250\n",
      "768/768 [==============================] - 0s 463us/step - loss: 0.4331 - accuracy: 0.7786\n",
      "Epoch 238/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4273 - accuracy: 0.7891\n",
      "Epoch 239/250\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4332 - accuracy: 0.7826\n",
      "Epoch 240/250\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 0.4293 - accuracy: 0.8034\n",
      "Epoch 241/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4263 - accuracy: 0.7917\n",
      "Epoch 242/250\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 0.4275 - accuracy: 0.7969\n",
      "Epoch 243/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4287 - accuracy: 0.7826\n",
      "Epoch 244/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4331 - accuracy: 0.7865\n",
      "Epoch 245/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4306 - accuracy: 0.7904\n",
      "Epoch 246/250\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4293 - accuracy: 0.7904\n",
      "Epoch 247/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4295 - accuracy: 0.7917\n",
      "Epoch 248/250\n",
      "768/768 [==============================] - 6s 7ms/step - loss: 0.4280 - accuracy: 0.7878\n",
      "Epoch 249/250\n",
      "768/768 [==============================] - 3s 4ms/step - loss: 0.4261 - accuracy: 0.7943\n",
      "Epoch 250/250\n",
      "768/768 [==============================] - 5s 7ms/step - loss: 0.4321 - accuracy: 0.7891\n"
     ]
    }
   ],
   "source": [
    "#Please post your solution here.\n",
    "#Feel free to add markdown and code cells as you need\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history1 = model.fit(X, Y, epochs=250, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 1s 713us/step\n",
      "Accuracy: 79.82\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X, Y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "c = accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By increasing the epoch the accuracy had been increased to 80%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6 (optional)\n",
    "\n",
    "Try similar steps for the multiclass tutorial:\n",
    "\n",
    "https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
